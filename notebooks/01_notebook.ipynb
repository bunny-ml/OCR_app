{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"widgets":{"application/vnd.jupyter.widget-state+json":{"0064a8d57342444daeb0fb338a3cf9d3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"02322c013fd9470cb4e5f3be045c3e7b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"03a57f9854814aa0b60e39ecf683d310":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4e9f137a0bf141c896c38ff64c2cb379","placeholder":"​","style":"IPY_MODEL_69bc4311cbd64068b9c8881232785da7","value":"special_tokens_map.json: 100%"}},"06a526387d704ca2b9b2659aa29246ff":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"06bc833cb57c4cbcb646de7f07d17eb3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"185009a252764eaabf0e839ed15b29ce":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0064a8d57342444daeb0fb338a3cf9d3","placeholder":"​","style":"IPY_MODEL_2573e12f0eab4896ae6079d44f6f93ed","value":"model.safetensors: 100%"}},"1a885e5a696e4a649af18e12c54eb6a0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_03a57f9854814aa0b60e39ecf683d310","IPY_MODEL_4653daef463c413bb9f5507ec87c86d0","IPY_MODEL_9ef0af0493fd4c138fb81c76f5017a21"],"layout":"IPY_MODEL_e1df803c91bb4ab19919aa0844d6c2cc"}},"1b78596f653640608da6c7c32e1d5e23":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_185009a252764eaabf0e839ed15b29ce","IPY_MODEL_83f51c5531714f51bedece1c1dcf0b7c","IPY_MODEL_4adaf36082ba4f3ab817d205ea085af0"],"layout":"IPY_MODEL_93cf8ad9663140ff8aa88e22fa7ac055"}},"1feed365d52a4371851cd3f918227e97":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"243d464f9eae42e4b8d8a3ec96a1637a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2573e12f0eab4896ae6079d44f6f93ed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2745f44d022441639de39498ae096c29":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_06bc833cb57c4cbcb646de7f07d17eb3","placeholder":"​","style":"IPY_MODEL_da22ab176d514ac095d19c365e7905ac","value":"tokenizer_config.json: "}},"28f07c1dd31e4be094ddb82c06054311":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"337586cf62bc42f3b9991b1504889415":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"34e090a2a5b841ee893fd09c31212957":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cee6cf30ddb54e11bff5b698749082cd","placeholder":"​","style":"IPY_MODEL_02322c013fd9470cb4e5f3be045c3e7b","value":" 190/190 [00:00&lt;00:00, 12.4kB/s]"}},"376f4b737a60462a9d82e498fee8148f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d74b538d2721428c97899883030f035c","placeholder":"​","style":"IPY_MODEL_d1838e3942bc496389506bf2eaed8bcd","value":" 456k/? [00:00&lt;00:00, 28.0MB/s]"}},"3b78e0efebf04ea19094b41c495f246a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2745f44d022441639de39498ae096c29","IPY_MODEL_7aec993985084f00a984f35b2609803c","IPY_MODEL_fef9b398f5b643be84af9a2c6a03f39d"],"layout":"IPY_MODEL_83279b3581cf4dc3b0d455c1cb64e0c7"}},"3e327623994e4236814268e14a31fc29":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"4653daef463c413bb9f5507ec87c86d0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ce4494bc8bfc46cda994e84295a4a238","max":772,"min":0,"orientation":"horizontal","style":"IPY_MODEL_28f07c1dd31e4be094ddb82c06054311","value":772}},"48afebd954454513a1aaf77e6b313235":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4989c8754738420a9072f177cfa12347":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4adaf36082ba4f3ab817d205ea085af0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1feed365d52a4371851cd3f918227e97","placeholder":"​","style":"IPY_MODEL_8730e6101342411ea31197a06d27b198","value":" 1.54G/1.54G [00:11&lt;00:00, 318MB/s]"}},"4e913400e3a34c9cac077603e411360c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e9f137a0bf141c896c38ff64c2cb379":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52db0d22d5da472fbd13e70a8c3eb823":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9bc1dbd1bf2c4f4f98229504af994b27","placeholder":"​","style":"IPY_MODEL_5737b27951c742f88dd0fd70fe234b26","value":"generation_config.json: 100%"}},"5737b27951c742f88dd0fd70fe234b26":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"58b73bbfae504e36bf5222a4c057a2de":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dc0eaa05d17a4208a234fabebaa18614","IPY_MODEL_c865b31882e74fd289d7ff785752562b","IPY_MODEL_db8a6f4082684d71b329f56f0462d9b2"],"layout":"IPY_MODEL_6ba46f96c7e644da82463c7e65fbbddd"}},"617b9f0188784f3ea73967d99cf1a615":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"624babba1bfb4baf95e16f341e17c058":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"65be60c2ebb84cefbf924f7e94607627":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_52db0d22d5da472fbd13e70a8c3eb823","IPY_MODEL_745665e2a80d4ae4838123dc8a0340f6","IPY_MODEL_34e090a2a5b841ee893fd09c31212957"],"layout":"IPY_MODEL_337586cf62bc42f3b9991b1504889415"}},"69bc4311cbd64068b9c8881232785da7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6ba46f96c7e644da82463c7e65fbbddd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d3c5db7b349419fbe6b51881070021b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f5c3e8068da4fbe8cf497b1611d693f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6f772e4d89074ea4ab22c7768fff4d0d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"745665e2a80d4ae4838123dc8a0340f6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c51a27a764f84c06b7a94b938f64a866","max":190,"min":0,"orientation":"horizontal","style":"IPY_MODEL_82bb1096519e4f22be9d1201a05d5178","value":190}},"7508cb660331434ba89fb1ba889c263f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9557bacda3a947bba53b72b26e969a37","placeholder":"​","style":"IPY_MODEL_243d464f9eae42e4b8d8a3ec96a1637a","value":" 4.21k/? [00:00&lt;00:00, 419kB/s]"}},"750be30b44ec4ab1a5512075f42e3923":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_964905e909234f0cba300d4d1008fcc0","placeholder":"​","style":"IPY_MODEL_75ea4dafae374d5d963d0c81a76f46db","value":"preprocessor_config.json: 100%"}},"75a2ab76acf740d5a1d9bcc83920c188":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"75ea4dafae374d5d963d0c81a76f46db":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7aec993985084f00a984f35b2609803c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7bf8a0386710401fa0b1730c1018deb0","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9380d02aed7a4071b146f9bb86450181","value":1}},"7bf8a0386710401fa0b1730c1018deb0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"7dbae7e2612c4ce2b2619bf0e84e6c67":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8c06ea83909640118a4f2624679b2b7e","placeholder":"​","style":"IPY_MODEL_95546481679044bcb823f3cfb5771270","value":"merges.txt: "}},"7f0cec4c74bc494bbd88b2bc28d5dc49":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_750be30b44ec4ab1a5512075f42e3923","IPY_MODEL_d8974a01f2f84432a434b2cb3d2703d9","IPY_MODEL_d3e7775bf8944bffa9184612d53da545"],"layout":"IPY_MODEL_4e913400e3a34c9cac077603e411360c"}},"7f7746d3d17d43a4882cdf76cab4e277":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e2d56aebbb2d4c408f6c0bf559e99824","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cefa85663d90410f8cd61284d975e9bb","value":1}},"82bb1096519e4f22be9d1201a05d5178":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"83279b3581cf4dc3b0d455c1cb64e0c7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"83f51c5531714f51bedece1c1dcf0b7c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c18370af016049e0922467839d801fe0","max":1537156244,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f586f4948b4d4878aef35342c749d1f1","value":1537156244}},"8612f608a982438a907b1b24863cf805":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8730e6101342411ea31197a06d27b198":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8c06ea83909640118a4f2624679b2b7e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ca125a835eb4a8480b9ae9d95ed40fe":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8fcab295983249618b1f2bd4a3177a15":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7dbae7e2612c4ce2b2619bf0e84e6c67","IPY_MODEL_cb3b78a413914cc58670b19c7a8abb98","IPY_MODEL_376f4b737a60462a9d82e498fee8148f"],"layout":"IPY_MODEL_b7d1d75bcb7641e4a1f2901e272ad23d"}},"9380d02aed7a4071b146f9bb86450181":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"93cf8ad9663140ff8aa88e22fa7ac055":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95546481679044bcb823f3cfb5771270":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9557bacda3a947bba53b72b26e969a37":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"964905e909234f0cba300d4d1008fcc0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9bc1dbd1bf2c4f4f98229504af994b27":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ead9fc960754e63b669f60fb4479bf2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ef0af0493fd4c138fb81c76f5017a21":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6f772e4d89074ea4ab22c7768fff4d0d","placeholder":"​","style":"IPY_MODEL_cb273debeef74d11b3d971cec979acd9","value":" 772/772 [00:00&lt;00:00, 64.2kB/s]"}},"b3e0c2daed224274a48969d4eedc149b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b7d1d75bcb7641e4a1f2901e272ad23d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c05e84337ba948e5bfca0f470e8aca82":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"c18370af016049e0922467839d801fe0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c409e909c2284da2afe212a3a533f66d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c51a27a764f84c06b7a94b938f64a866":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c865b31882e74fd289d7ff785752562b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e327623994e4236814268e14a31fc29","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_48afebd954454513a1aaf77e6b313235","value":1}},"cb273debeef74d11b3d971cec979acd9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cb3b78a413914cc58670b19c7a8abb98":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c05e84337ba948e5bfca0f470e8aca82","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_06a526387d704ca2b9b2659aa29246ff","value":1}},"ce4494bc8bfc46cda994e84295a4a238":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cee6cf30ddb54e11bff5b698749082cd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cefa85663d90410f8cd61284d975e9bb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d0886e106dd74c3ea3d0039974643b5f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c409e909c2284da2afe212a3a533f66d","placeholder":"​","style":"IPY_MODEL_da110035e4824912a12ebde812f58359","value":"config.json: "}},"d1838e3942bc496389506bf2eaed8bcd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d3e7775bf8944bffa9184612d53da545":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8ca125a835eb4a8480b9ae9d95ed40fe","placeholder":"​","style":"IPY_MODEL_fcf500a6ba16465f88fef22525b8f06f","value":" 224/224 [00:00&lt;00:00, 13.4kB/s]"}},"d74b538d2721428c97899883030f035c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d8974a01f2f84432a434b2cb3d2703d9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6d3c5db7b349419fbe6b51881070021b","max":224,"min":0,"orientation":"horizontal","style":"IPY_MODEL_75a2ab76acf740d5a1d9bcc83920c188","value":224}},"da110035e4824912a12ebde812f58359":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"da22ab176d514ac095d19c365e7905ac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"db8a6f4082684d71b329f56f0462d9b2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9ead9fc960754e63b669f60fb4479bf2","placeholder":"​","style":"IPY_MODEL_624babba1bfb4baf95e16f341e17c058","value":" 899k/? [00:00&lt;00:00, 26.7MB/s]"}},"dc0eaa05d17a4208a234fabebaa18614":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b3e0c2daed224274a48969d4eedc149b","placeholder":"​","style":"IPY_MODEL_4989c8754738420a9072f177cfa12347","value":"vocab.json: "}},"e1df803c91bb4ab19919aa0844d6c2cc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2d56aebbb2d4c408f6c0bf559e99824":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"e60cc461d77c4012988c93c279d2a9cb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d0886e106dd74c3ea3d0039974643b5f","IPY_MODEL_7f7746d3d17d43a4882cdf76cab4e277","IPY_MODEL_7508cb660331434ba89fb1ba889c263f"],"layout":"IPY_MODEL_8612f608a982438a907b1b24863cf805"}},"f586f4948b4d4878aef35342c749d1f1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fcf500a6ba16465f88fef22525b8f06f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fef9b398f5b643be84af9a2c6a03f39d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_617b9f0188784f3ea73967d99cf1a615","placeholder":"​","style":"IPY_MODEL_6f5c3e8068da4fbe8cf497b1611d693f","value":" 1.12k/? [00:00&lt;00:00, 103kB/s]"}}}},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1821108,"sourceType":"datasetVersion","datasetId":1081982}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"dd08bb8e-d466-4237-a7bc-3572c3d0ba6f","cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nwarnings.filterwarnings(\"ignore\", message=\"os.fork() was called. os.fork() is incompatible with multithreaded code\", category=RuntimeWarning)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:03:11.553530Z","iopub.execute_input":"2025-12-08T14:03:11.554085Z","iopub.status.idle":"2025-12-08T14:03:11.557887Z","shell.execute_reply.started":"2025-12-08T14:03:11.554064Z","shell.execute_reply":"2025-12-08T14:03:11.557309Z"}},"outputs":[],"execution_count":38},{"id":"231ced73","cell_type":"code","source":"!pip install --upgrade --quiet transformers peft accelerate bitsandbytes\n!pip install evaluate jiwer\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T11:52:12.337244Z","iopub.execute_input":"2025-12-08T11:52:12.337965Z","iopub.status.idle":"2025-12-08T11:53:52.359959Z","shell.execute_reply.started":"2025-12-08T11:52:12.337933Z","shell.execute_reply":"2025-12-08T11:53:52.359220Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m112.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m556.4/556.4 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.9/380.9 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m92.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m119.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m86.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mCollecting evaluate\n  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\nCollecting jiwer\n  Downloading jiwer-4.0.0-py3-none-any.whl.metadata (3.3 kB)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.4.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.4.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.5)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.6.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.18)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.10.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.36.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (25.0)\nRequirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from jiwer) (8.3.0)\nCollecting rapidfuzz>=3.9.7 (from jiwer)\n  Downloading rapidfuzz-3.14.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (12 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.20.0)\nCollecting pyarrow>=21.0.0 (from datasets>=2.0.0->evaluate)\n  Downloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\nRequirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (0.28.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.3)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.2.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.10.5)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (4.11.0)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets>=2.0.0->evaluate) (0.16.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1.0.0->datasets>=2.0.0->evaluate) (1.3.1)\nDownloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading jiwer-4.0.0-py3-none-any.whl (23 kB)\nDownloading rapidfuzz-3.14.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (47.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: rapidfuzz, pyarrow, jiwer, evaluate\n  Attempting uninstall: pyarrow\n    Found existing installation: pyarrow 19.0.1\n    Uninstalling pyarrow-19.0.1:\n      Successfully uninstalled pyarrow-19.0.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\npylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\ncudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\ncudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed evaluate-0.4.6 jiwer-4.0.0 pyarrow-22.0.0 rapidfuzz-3.14.3\n","output_type":"stream"}],"execution_count":2},{"id":"fda90cfe-7ad7-426a-bc4b-5e4520236133","cell_type":"code","source":"!pip install protobuf==4.25.3","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T11:55:23.817849Z","iopub.execute_input":"2025-12-08T11:55:23.818148Z","iopub.status.idle":"2025-12-08T11:55:27.954032Z","shell.execute_reply.started":"2025-12-08T11:55:23.818124Z","shell.execute_reply":"2025-12-08T11:55:27.953095Z"}},"outputs":[{"name":"stdout","text":"Collecting protobuf==4.25.3\n  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\nDownloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: protobuf\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 6.33.0\n    Uninstalling protobuf-6.33.0:\n      Successfully uninstalled protobuf-6.33.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\nopentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 4.25.3 which is incompatible.\na2a-sdk 0.3.10 requires protobuf>=5.29.5, but you have protobuf 4.25.3 which is incompatible.\nray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\npydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\npydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\nydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.3 which is incompatible.\ngrpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.3 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed protobuf-4.25.3\n","output_type":"stream"}],"execution_count":5},{"id":"08b945d3","cell_type":"code","source":"\nimport time\nimport math\nimport numpy as np\nfrom transformers import TrOCRProcessor, VisionEncoderDecoderModel\nimport torch\nimport evaluate\nfrom tqdm import tqdm\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:03:16.113399Z","iopub.execute_input":"2025-12-08T14:03:16.114128Z","iopub.status.idle":"2025-12-08T14:03:16.117948Z","shell.execute_reply.started":"2025-12-08T14:03:16.114101Z","shell.execute_reply":"2025-12-08T14:03:16.117139Z"}},"outputs":[],"execution_count":39},{"id":"79ac0c5d","cell_type":"code","source":"import torch\nfrom transformers import TrOCRProcessor, VisionEncoderDecoderModel\nfrom peft import LoraConfig, get_peft_model\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# 1. Load processor first\nprocessor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-small-handwritten\")\n\n# 2. Load the base model\nbase_model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-small-handwritten\")\n\n# --- CRITICAL FIX 1: Resize the Decoder Head (Solves RuntimeError) ---\nbase_model.decoder.resize_token_embeddings(len(processor.tokenizer))\n# --- END CRITICAL FIX 1 ---\n\n\n# 3. Set required generation config IDs\nbase_model.config.decoder_start_token_id = processor.tokenizer.bos_token_id\nbase_model.config.pad_token_id = processor.tokenizer.pad_token_id\nbase_model.config.eos_token_id = processor.tokenizer.eos_token_id\nbase_model.config.vocab_size = base_model.decoder.config.vocab_size\n\n\n# --- CRITICAL FIX 2: Patch Base Decoder Config (Solves Checkpoint Warning) ---\n# Ensure the configuration object for the DECODER itself has the vocab_size set.\nbase_model.decoder.config.vocab_size = len(processor.tokenizer)\nprint(\"Patched base decoder config.\")\n# --- END CRITICAL FIX 2 ---\n\n\n# 4. Define and apply LoRA\nlora_config = LoraConfig(\n    r=8,\n    lora_alpha=16,\n    target_modules=[\"q_proj\", \"v_proj\"],\n    lora_dropout=0.05,\n    bias=\"none\",\n)\n\n# Apply LoRA to base_model to create the PEFT-wrapped model\nmodel = get_peft_model(base_model, lora_config)\nmodel.print_trainable_parameters()\n\n# 5. Final safety patches (on PEFT model config)\nmodel.config.vocab_size = processor.tokenizer.vocab_size\nmodel.config.decoder.vocab_size = processor.tokenizer.vocab_size \nprint(f\"Patched PEFT model config with vocab_size: {model.config.vocab_size}\")\n\n# 6. Move the PEFT-wrapped model to the device\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T15:19:00.868161Z","iopub.execute_input":"2025-12-08T15:19:00.868456Z","iopub.status.idle":"2025-12-08T15:19:05.485263Z","shell.execute_reply.started":"2025-12-08T15:19:00.868435Z","shell.execute_reply":"2025-12-08T15:19:05.484524Z"}},"outputs":[{"name":"stderr","text":"Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-small-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Patched base decoder config.\ntrainable params: 104,448 || all params: 61,679,616 || trainable%: 0.1693\nPatched PEFT model config with vocab_size: 64002\n","output_type":"stream"},{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"PeftModel(\n  (base_model): LoraModel(\n    (model): VisionEncoderDecoderModel(\n      (encoder): DeiTModel(\n        (embeddings): DeiTEmbeddings(\n          (patch_embeddings): DeiTPatchEmbeddings(\n            (projection): Conv2d(3, 384, kernel_size=(16, 16), stride=(16, 16))\n          )\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n        (encoder): DeiTEncoder(\n          (layer): ModuleList(\n            (0-11): 12 x DeiTLayer(\n              (attention): DeiTAttention(\n                (attention): DeiTSelfAttention(\n                  (query): Linear(in_features=384, out_features=384, bias=True)\n                  (key): Linear(in_features=384, out_features=384, bias=True)\n                  (value): Linear(in_features=384, out_features=384, bias=True)\n                )\n                (output): DeiTSelfOutput(\n                  (dense): Linear(in_features=384, out_features=384, bias=True)\n                  (dropout): Dropout(p=0.0, inplace=False)\n                )\n              )\n              (intermediate): DeiTIntermediate(\n                (dense): Linear(in_features=384, out_features=1536, bias=True)\n                (intermediate_act_fn): GELUActivation()\n              )\n              (output): DeiTOutput(\n                (dense): Linear(in_features=1536, out_features=384, bias=True)\n                (dropout): Dropout(p=0.0, inplace=False)\n              )\n              (layernorm_before): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n              (layernorm_after): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n            )\n          )\n        )\n        (layernorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n        (pooler): DeiTPooler(\n          (dense): Linear(in_features=384, out_features=384, bias=True)\n          (activation): Tanh()\n        )\n      )\n      (decoder): TrOCRForCausalLM(\n        (model): TrOCRDecoderWrapper(\n          (decoder): TrOCRDecoder(\n            (embed_tokens): TrOCRScaledWordEmbedding(64002, 256, padding_idx=1)\n            (embed_positions): TrOCRLearnedPositionalEmbedding(514, 256)\n            (layernorm_embedding): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n            (layers): ModuleList(\n              (0-5): 6 x TrOCRDecoderLayer(\n                (self_attn): TrOCRAttention(\n                  (k_proj): Linear(in_features=256, out_features=256, bias=True)\n                  (v_proj): lora.Linear(\n                    (base_layer): Linear(in_features=256, out_features=256, bias=True)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.05, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=256, out_features=8, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=8, out_features=256, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                    (lora_magnitude_vector): ModuleDict()\n                  )\n                  (q_proj): lora.Linear(\n                    (base_layer): Linear(in_features=256, out_features=256, bias=True)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.05, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=256, out_features=8, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=8, out_features=256, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                    (lora_magnitude_vector): ModuleDict()\n                  )\n                  (out_proj): Linear(in_features=256, out_features=256, bias=True)\n                )\n                (activation_fn): ReLU()\n                (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n                (encoder_attn): TrOCRAttention(\n                  (k_proj): Linear(in_features=384, out_features=256, bias=True)\n                  (v_proj): lora.Linear(\n                    (base_layer): Linear(in_features=384, out_features=256, bias=True)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.05, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=384, out_features=8, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=8, out_features=256, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                    (lora_magnitude_vector): ModuleDict()\n                  )\n                  (q_proj): lora.Linear(\n                    (base_layer): Linear(in_features=256, out_features=256, bias=True)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.05, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=256, out_features=8, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=8, out_features=256, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                    (lora_magnitude_vector): ModuleDict()\n                  )\n                  (out_proj): Linear(in_features=256, out_features=256, bias=True)\n                )\n                (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n                (fc1): Linear(in_features=256, out_features=1024, bias=True)\n                (fc2): Linear(in_features=1024, out_features=256, bias=True)\n                (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n              )\n            )\n          )\n        )\n        (output_projection): Linear(in_features=256, out_features=64002, bias=False)\n      )\n    )\n  )\n)"},"metadata":{}}],"execution_count":62},{"id":"c1e6fca2","cell_type":"code","source":"# If model is PEFT-wrapped, ensuring it reports trainable params:\ntrainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\ntotal = sum(p.numel() for p in model.parameters())\nprint(f\"Trainable params: {trainable:,} / Total params: {total:,}\")\n\n# training hyperparams (tweak as needed)\nnum_epochs = 2\naccum_steps = 8\nlearning_rate = 5e-5\ngrad_clip = 1.0\nsave_every_n_steps = 500\noutput_dir = \"./trocr_lora_manual\"\n\n# optimizer\noptimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate)\n\n# mixed precision scaler (Fix for FutureWarning, and optimization)\nuse_amp = torch.cuda.is_available()\n# Use torch.amp.GradScaler instead of the deprecated torch.cuda.amp.GradScaler\nscaler = torch.amp.GradScaler(enabled=use_amp) if use_amp else None\n\n# metrics\nwer_metric = evaluate.load(\"wer\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T15:19:06.999106Z","iopub.execute_input":"2025-12-08T15:19:06.999874Z","iopub.status.idle":"2025-12-08T15:19:08.212404Z","shell.execute_reply.started":"2025-12-08T15:19:06.999838Z","shell.execute_reply":"2025-12-08T15:19:08.211657Z"}},"outputs":[{"name":"stdout","text":"Trainable params: 104,448 / Total params: 61,679,616\n","output_type":"stream"}],"execution_count":63},{"id":"1cf86d5a","cell_type":"code","source":"\n# helper: generate predictions for a batch of pixel_values (tensor on device)\ndef generate_preds(batch_pixel_values, max_length=64, num_beams=4):\n    # batch_pixel_values: tensor (B, C, H, W)\n    model.eval()\n    with torch.no_grad():\n        # model.generate expects pixel_values on the device\n        generated_ids = model.generate(\n            pixel_values=batch_pixel_values,\n            max_length=max_length,\n            num_beams=num_beams,\n            early_stopping=True,\n            pad_token_id=processor.tokenizer.pad_token_id,\n            eos_token_id=processor.tokenizer.eos_token_id,\n            decoder_start_token_id=processor.tokenizer.bos_token_id,\n        )\n        preds = processor.batch_decode(generated_ids, skip_special_tokens=True)\n    return preds\n\n# eval function (computes wer + exact match)\ndef evaluate_epoch(eval_loader, max_length=64, num_beams=4, limit=None):\n    model.eval()\n    pred_texts = []\n    true_texts = []\n    with torch.no_grad():\n        for i, batch in enumerate(tqdm(eval_loader, desc=\"Eval\")):\n            # batch keys: pixel_values, labels (as in collate_fn)\n            pixel_values = batch[\"pixel_values\"].to(device)\n            labels = batch[\"labels\"].to(device)\n\n            # decode true labels to text (convert -100 -> pad token id first)\n            labels_for_decoding = labels.clone()\n            labels_for_decoding[labels_for_decoding == -100] = processor.tokenizer.pad_token_id\n            label_strs = processor.batch_decode(labels_for_decoding, skip_special_tokens=True)\n            true_texts.extend([s.strip() for s in label_strs])\n\n            preds = generate_preds(pixel_values, max_length=max_length, num_beams=num_beams)\n            pred_texts.extend([s.strip() for s in preds])\n\n            if limit and i >= limit:\n                break\n\n    # compute metrics\n    wer = wer_metric.compute(predictions=pred_texts, references=true_texts)\n    exact = sum(1 for a,b in zip(pred_texts, true_texts) if a.strip()==b.strip()) / max(1, len(pred_texts))\n    return {\"wer\": wer, \"exact_match\": exact, \"preds\": pred_texts[:5], \"refs\": true_texts[:5]}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T15:19:15.843978Z","iopub.execute_input":"2025-12-08T15:19:15.844246Z","iopub.status.idle":"2025-12-08T15:19:15.852338Z","shell.execute_reply.started":"2025-12-08T15:19:15.844227Z","shell.execute_reply":"2025-12-08T15:19:15.851493Z"}},"outputs":[],"execution_count":64},{"id":"12a21f85","cell_type":"code","source":"import os\nimport pandas as pd\nfrom PIL import Image\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom transformers import TrOCRProcessor\n\n# --- REVISED HandwritingDataset CLASS ---\nclass HandwritingDataset(Dataset):\n    def __init__(self, df, processor, max_target_length=64):\n        self.df = df\n        self.processor = processor\n        self.max_target_length = max_target_length\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img_path = row[\"full_path\"]\n        label = row[\"IDENTITY\"]\n\n        image = Image.open(img_path).convert(\"RGB\")\n\n        # 🚀 FIX 1: Separate image processing (feature_extractor) and text tokenization (tokenizer)\n        # This prevents the 'Unused or unrecognized kwargs' warnings.\n        pixel_values = self.processor.feature_extractor(\n            image,\n            return_tensors=\"pt\"\n        ).pixel_values.squeeze(0)\n\n        # Tokenize text/labels separately\n        labels = self.processor.tokenizer(\n            label,\n            padding=\"max_length\",\n            max_length=self.max_target_length,\n            truncation=True,\n            return_tensors=\"pt\"\n        ).input_ids.squeeze(0)\n\n        labels[labels == self.processor.tokenizer.pad_token_id] = -100\n\n        return {\n            \"pixel_values\": pixel_values,\n            \"labels\": labels\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:39:45.813717Z","iopub.execute_input":"2025-12-08T14:39:45.813985Z","iopub.status.idle":"2025-12-08T14:39:45.820635Z","shell.execute_reply.started":"2025-12-08T14:39:45.813966Z","shell.execute_reply":"2025-12-08T14:39:45.819987Z"}},"outputs":[],"execution_count":50},{"id":"3d6142a9","cell_type":"code","source":"import os\nimport re\nimport pandas as pd\n\ndef load_and_clean_csv(csv_path, img_dir):\n    # Load data\n    df = pd.read_csv(csv_path)\n\n    # 1. Path construction (Fix for File Not Found / cross-platform compatibility)\n    # Use os.path.join for robust path building\n    df[\"full_path\"] = df[\"FILENAME\"].apply(lambda x: os.path.join(img_dir, x))\n\n    # Ensure IDENTITY is string and filter empty labels\n    df[\"IDENTITY\"] = df[\"IDENTITY\"].astype(str)\n    df = df[df[\"IDENTITY\"].str.strip().str.len() > 0].copy()\n\n    # Normalize IDENTITY: lowercase, remove non-alphanumeric (as per original intent)\n    # Using 'copy()' to avoid a SettingWithCopyWarning\n    df[\"IDENTITY\"] = df[\"IDENTITY\"].str.lower().str.replace(r\"[^a-z0-9\\s]\", \"\", regex=True).str.strip()\n\n    # 2. Remove rows where the image file does not exist (Fix for \"File not found during training\")\n    # 3. Reset index after filtering to prevent `ValueError: Item wrong length`\n    df = df.loc[df[\"full_path\"].apply(os.path.exists)].reset_index(drop=True)\n\n    print(f\"Loaded and cleaned {len(df)} lines from {csv_path}\")\n\n    return df\n\n# Example usage (assuming your original path variables are set correctly):\n# train_df = load_and_clean_csv(train_csv, train_img_dir)\n# valid_df = load_and_clean_csv(valid_csv, valid_img_dir)\n# test_df = load_and_clean_csv(test_csv, test_img_dir)\n\n# ... followed by dataset/dataloader creation ...\n\n\npath = \"/kaggle/input/handwriting-recognitionocr\"\n\ntrain_csv = f\"{path}/CSV/written_name_train.csv\"\nvalid_csv = f\"{path}/CSV/written_name_test.csv\"\ntest_csv  = f\"{path}/CSV/written_name_validation.csv\"\n\ntrain_img_dir = f\"{path}/train_v2/train\"\nvalid_img_dir = f\"{path}/test_v2/test\"\ntest_img_dir  = f\"{path}/validation_v2/validation\"\n\n# Cleaned DataFrames\ntrain_df = load_and_clean_csv(train_csv, train_img_dir)\nvalid_df = load_and_clean_csv(valid_csv, valid_img_dir)\ntest_df  = load_and_clean_csv(test_csv,  test_img_dir)\n\n\ntrain_dataset = HandwritingDataset(train_df, processor)\nvalid_dataset = HandwritingDataset(valid_df,  processor)\ntest_dataset  = HandwritingDataset(test_df,   processor)\n\ndef collate_skip_none(batch):\n    batch = [b for b in batch if b is not None]\n    return torch.utils.data.default_collate(batch)\n\n\n\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=16,\n    shuffle=False,\n    num_workers=0,\n    pin_memory=True,\n    collate_fn=collate_skip_none,\n)\n\neval_loader = DataLoader(\n    valid_dataset,\n    batch_size=16,\n    shuffle=False,\n    num_workers=0,\n    pin_memory=True,\n    collate_fn=collate_skip_none,\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:40:11.313600Z","iopub.execute_input":"2025-12-08T14:40:11.314111Z","iopub.status.idle":"2025-12-08T14:50:09.945925Z","shell.execute_reply.started":"2025-12-08T14:40:11.314087Z","shell.execute_reply":"2025-12-08T14:50:09.945225Z"}},"outputs":[{"name":"stdout","text":"Loaded and cleaned 330961 lines from /kaggle/input/handwriting-recognitionocr/CSV/written_name_train.csv\nLoaded and cleaned 41370 lines from /kaggle/input/handwriting-recognitionocr/CSV/written_name_test.csv\nLoaded and cleaned 41370 lines from /kaggle/input/handwriting-recognitionocr/CSV/written_name_validation.csv\n","output_type":"stream"}],"execution_count":53},{"id":"01b1b6d1","cell_type":"code","source":"import time\nimport os\nimport torch\nfrom tqdm.auto import tqdm\n\n# Ensure all external variables (num_epochs, optimizer, scaler, etc.) are defined \n# in the cells above this one.\n\nglobal_step = 0\nbest_wer = float(\"inf\")\n\nfor epoch in range(num_epochs):\n    model.train()\n    epoch_loss = 0.0\n    start = time.time()\n    \n    # CRITICAL FIX: leave=False keeps the progress bar output clean\n    pbar = tqdm(total=len(train_loader), desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\", leave=False)\n    \n    optimizer.zero_grad()\n\n    for step, batch in enumerate(train_loader):\n        pixel_values = batch[\"pixel_values\"].to(device)      # (B, C, H, W)\n        labels = batch[\"labels\"].to(device)                  # (B, L) with -100 for padding\n\n        # Use autocast from torch.cuda.amp directly (standard practice)\n        with torch.cuda.amp.autocast(enabled=use_amp):\n            # forward pass (VisionEncoderDecoder model accepts pixel_values and labels)\n            outputs = model(pixel_values=pixel_values, labels=labels)\n            loss = outputs.loss / accum_steps  # average for accumulation\n\n        scaler.scale(loss).backward()\n        epoch_loss += loss.item() * accum_steps  # multiply back\n\n        if (step + 1) % accum_steps == 0:\n            # gradient clipping (unscale first)\n            scaler.unscale_(optimizer)\n            torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n\n            scaler.step(optimizer)\n            scaler.update()\n            optimizer.zero_grad()\n            global_step += 1\n\n            if global_step % 50 == 0:\n                # Use current global step for loss tracking\n                # NOTE: Ensure global_step starts at 0 and increments correctly\n                pbar.set_postfix({\"loss\": f\"{epoch_loss/global_step:.4f}\"})\n\n        # NO INTERMEDIATE SAVE BLOCK HERE (Removed the problematic global_step % save_every_n_steps == 0)\n        \n        pbar.update(1) # Update the progress bar for every batch\n    \n    # --- END OF BATCH LOOP (DEDENTED) ---\n    pbar.close()\n    \n    epoch_time = time.time() - start\n    avg_loss = epoch_loss / max(1, len(train_loader))\n    print(f\"Epoch {epoch+1} done — avg_loss: {avg_loss:.4f} — time: {epoch_time/60:.2f} min\")\n\n    # evaluate on full validation set\n    metrics = evaluate_epoch(eval_loader, max_length=64, num_beams=4, limit=None)\n    print(f\"Validation — WER: {metrics['wer']:.4f}  Exact: {metrics['exact_match']:.4f}\")\n    print(\"Sample preds:\", metrics[\"preds\"])\n    print(\"Sample refs :\", metrics[\"refs\"])\n\n    # save best\n    if metrics[\"wer\"] < best_wer:\n        best_wer = metrics[\"wer\"]\n        os.makedirs(output_dir, exist_ok=True)\n        print(\"New best — saving model to\", output_dir)\n        \n        # *** CRITICAL PATCH: Guaranteed Vocab Size for Saving (Final/Best) ***\n        # Apply patch just before saving.\n        try:\n            model.config.vocab_size = len(processor.tokenizer)\n            model.config.decoder.vocab_size = len(processor.tokenizer)\n        except:\n            pass\n            \n        # Try the standard save first\n        try:\n            model.save_pretrained(output_dir)\n            processor.save_pretrained(output_dir)\n            print(\"Successfully saved best model!\")\n        except Exception as e:\n            # *** ULTIMATE FALLBACK: Manually save LoRA weights if config save fails ***\n            print(f\"Failed to save model: {e}. Attempting manual LoRA adapter save...\")\n            try:\n                # This saves only the small, essential adapter weights, which is all you need for PEFT.\n                torch.save(model.state_dict(), os.path.join(output_dir, \"adapter_weights_manual.pt\"))\n                processor.save_pretrained(output_dir) # Still save the processor config\n                print(f\"✅ SUCCESS: Manual LoRA adapter weights saved to {output_dir}/adapter_weights_manual.pt\")\n            except Exception as manual_e:\n                print(f\"CRITICAL ERROR: Failed manual save. Your weights are only in GPU memory. {manual_e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T18:16:06.656197Z","iopub.execute_input":"2025-12-08T18:16:06.656718Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Epoch 1/2:   0%|          | 0/20686 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0584f6f61bfd48bea755e74e45b3f4ed"}},"metadata":{}}],"execution_count":null},{"id":"b8589962","cell_type":"code","source":"import os\nimport torch\n\n# Define the directory where you want to save the checkpoint\n# (Use a new directory name just in case)\nFINAL_SAVE_DIR = \"./trocr_lora_final_save\"\nos.makedirs(FINAL_SAVE_DIR, exist_ok=True)\n\nprint(\"Attempting manual save...\")\n\n# *** Final, Most Aggressive Configuration Patch ***\n# Patch the attributes one final time directly on the live model configuration \n# before calling the save function.\ntry:\n    model.config.vocab_size = len(processor.tokenizer)\n    model.config.decoder.vocab_size = len(processor.tokenizer)\n    print(\"Configuration patched successfully.\")\nexcept Exception as e:\n    print(f\"Warning: Configuration patch failed: {e}\")\n\n# --- CRITICAL SAVE STEP ---\n# 1. Save the PEFT adapter weights (the LoRA changes)\nmodel.save_pretrained(FINAL_SAVE_DIR)\n# 2. Save the processor (tokenizer and feature extractor)\nprocessor.save_pretrained(FINAL_SAVE_DIR)\n\nprint(f\"\\n✅ SUCCESS! Your model progress has been saved to: {FINAL_SAVE_DIR}\")\nprint(\"You can load the model back using: model = PeftModel.from_pretrained(base_model, FINAL_SAVE_DIR)\")\nprint(\"Training finished. Best WER:\", best_wer)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T18:16:01.688108Z","iopub.status.idle":"2025-12-08T18:16:01.688442Z","shell.execute_reply.started":"2025-12-08T18:16:01.688270Z","shell.execute_reply":"2025-12-08T18:16:01.688286Z"}},"outputs":[],"execution_count":null},{"id":"9722eee4","cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}